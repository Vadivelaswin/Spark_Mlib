{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Module\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"Sentiment analysis in Twitter\"\n",
    "spark = SparkSession.builder.appName('appName').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spark modules\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF,Tokenizer,StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+--------------------+\n",
      "|ItemID|Sentiment|SentimentSource|       SentimentText|\n",
      "+------+---------+---------------+--------------------+\n",
      "|  1038|        1|   Sentiment140|that film is fant...|\n",
      "|  1804|        1|   Sentiment140|this music is rea...|\n",
      "|  1693|        0|   Sentiment140|winter is terribl...|\n",
      "+------+---------+---------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read data file into Spark DataFrame\n",
    "\n",
    "#read csv file into dataFrame with automatically inferred schema\n",
    "\n",
    "tweets_csv = spark.read.csv('dataset/tweets.csv',inferSchema=True,header=True)\n",
    "\n",
    "tweets_csv.show(truncate=True,n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select only sentiment and sentiment column and cast sentiment column data into integer\n",
    "\n",
    "data = tweets_csv.select(\"SentimentText\",col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "\n",
    "data.show(truncate=False,n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Data into training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows 1365 ,Testing data rows 567\n"
     ]
    }
   ],
   "source": [
    "#divide data, 70% and training data 30% for testing\n",
    "\n",
    "dividedData = data.randomSplit([0.7,0.3])\n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "train_rows = trainingData.count()\n",
    "test_rows = testingData.count()\n",
    "print (\"Training data rows\",train_rows, \",Testing data rows\",test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+\n",
      "|SentimentText            |label|SentimentWords                |\n",
      "+-------------------------+-----+------------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Seperate SentimentText into individual words using tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"SentimentText\",outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "tokenizedTrain.show(truncate=False,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|SentimentText            |label|SentimentWords                |MeaningfulWords            |\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |[adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|[adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |[adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |[adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|[adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words (not req words to be features)\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(),outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(truncate=False,n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words feature into numerical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[65702,69876,108823],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[61111,65702,69876],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #favorite] |(262144,[65702,69876,156543],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #loveit]   |(262144,[65702,65728,69876],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #thumbs-up]|(262144,[3984,65702,69876],[1.0,1.0,1.0])  |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol = swr.getOutputCol(),outputCol=\"features\")\n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\"label\",\"MeaningfulWords\",\"features\")\n",
    "numericTrainData.show(truncate=False,n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our classifier model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol='label',featuresCol=\"features\",maxIter=10,regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print(\"Training is done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[65702,69876,108823],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[61111,65702,69876],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #favorite] |(262144,[65702,69876,156543],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #loveit]   |(262144,[65702,65728,69876],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #thumbs-up]|(262144,[3984,65702,69876],[1.0,1.0,1.0])  |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare testing data\n",
    "\n",
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTrain).select(\"label\",\"MeaningfulWords\",\"features\")\n",
    "numericTest.show(truncate=False,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[65702,69876,108823],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[61111,65702,69876],[1.0,1.0,1.0]) |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numericTest.show(truncate=False,n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict testing and calculate the accuracy model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+-----+\n",
      "|MeaningfulWords            |prediction|Label|\n",
      "+---------------------------+----------+-----+\n",
      "|[adore, cheese, #bestever] |1.0       |1    |\n",
      "|[adore, cheese, #brilliant]|1.0       |1    |\n",
      "|[adore, cheese, #favorite] |1.0       |1    |\n",
      "|[adore, cheese, #loveit]   |1.0       |1    |\n",
      "|[adore, cheese, #thumbs-up]|1.0       |1    |\n",
      "+---------------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "correct prediction: 1344 ,total data: 1365 ,accuracy: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select(\"MeaningfulWords\",\"prediction\",\"Label\")\n",
    "predictionFinal.show(truncate=False,n=5)\n",
    "correctPrediction = predictionFinal.filter(predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "\n",
    "print(\"correct prediction:\", correctPrediction, \",total data:\" , totalData, \",accuracy:\",correctPrediction/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
